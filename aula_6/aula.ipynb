{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações básicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download de recursos NLTK (se necessário)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo - críticas de filmes (simplificadas)\n",
    "textos = [\n",
    "    \"Este filme é incrível, adorei a atuação do protagonista\",\n",
    "    \"A direção de fotografia é espetacular e o roteiro é envolvente\",\n",
    "    \"Péssimo filme, desperdicei meu tempo assistindo isso\",\n",
    "    \"Os atores são talentosos mas o roteiro é fraco\",\n",
    "    \"Cinematografia belíssima, recomendo assistir no cinema\",\n",
    "    \"Não gostei da história, personagens mal desenvolvidos\",\n",
    "    \"A trilha sonora combina perfeitamente com as cenas\",\n",
    "    \"Filme entediante, previsível do início ao fim\",\n",
    "    \"Os efeitos especiais são impressionantes, tecnologia de ponta\",\n",
    "    \"História emocionante, chorei no final do filme\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto 1: Este filme é incrível, adorei a atuação do protagonista\n",
      "Texto 2: A direção de fotografia é espetacular e o roteiro é envolvente\n",
      "Texto 3: Péssimo filme, desperdicei meu tempo assistindo isso\n"
     ]
    }
   ],
   "source": [
    "# Verificando os dados\n",
    "for i, texto in enumerate(textos[:3]):  # Mostrando apenas os 3 primeiros\n",
    "    print(f\"Texto {i+1}: {texto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessar_texto(texto):\n",
    "    # Converter para minúsculas\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # Remover caracteres especiais e números\n",
    "    texto = re.sub(r'[^a-záàâãéèêíïóôõöúçñ ]', '', texto)\n",
    "\n",
    "    # Tokenizar\n",
    "    tokens = word_tokenize(texto)\n",
    "\n",
    "    # Remover stopwords (opcional, dependendo da aplicação)\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar pré-processamento a todos os textos\n",
    "textos_preprocessados = [preprocessar_texto(texto) for texto in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de texto original:\n",
      "Este filme é incrível, adorei a atuação do protagonista\n",
      "\n",
      "Depois do pré-processamento:\n",
      "['filme', 'incrível', 'adorei', 'atuação', 'protagonista']\n"
     ]
    }
   ],
   "source": [
    "# Verificar resultado\n",
    "print(\"Exemplo de texto original:\")\n",
    "print(textos[0])\n",
    "print(\"\\nDepois do pré-processamento:\")\n",
    "print(textos_preprocessados[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
